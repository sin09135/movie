{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5178c39c-938b-4072-bac3-99c97cb31a1d",
   "metadata": {},
   "source": [
    "## **JustWatch - Webscraping Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222019c-bd32-422e-862c-9e65b8be4aaf",
   "metadata": {},
   "source": [
    "### **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bb20c-2636-4019-9987-484e7653e09d",
   "metadata": {},
   "source": [
    "**JustWatch** website uses ajax to consumes their API using **GraphQL queries**. The data returns as a **JSON** file. To get the data all we need is the **requests** package. It will not be necessary any other package.\n",
    "\n",
    "> **If you wanna replicate, maybe you need to install some of the packages with PIP command.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea672dc8-0d16-4ae9-be08-bc5b501c8ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a93d41-97db-42a9-8a0e-a3d3d0ac5947",
   "metadata": {},
   "source": [
    "To get the data we need the **reference code** of the streaming to pass as a **GraphQL variable**. I collected an amount of great **streamings** references codes and parses as a **dictionary**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1e8be0-e047-4f94-ad71-656d9e8d2be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "streamings = dict(\n",
    "    amazon='amp',\n",
    "    disney='dnp',\n",
    "    darkmatter='dkm',\n",
    "    rakuten_viki='vik',\n",
    "    hbo='hbm',\n",
    "    netflix='nfx',\n",
    "    hulu='hlu',\n",
    "    paramount='pmp',\n",
    "    funimation='fmn',\n",
    "    crunchyroll='cru',\n",
    "    starz='stz',\n",
    "    appletv='atp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507df03-561c-4404-8566-68c5de93bcfa",
   "metadata": {},
   "source": [
    "Their **API** uses only one **endpoint** to get the queries. So, we need just change the **parameters** and the **query** to collect the streamings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f2d595-d645-4503-bf3a-bdd6d2583008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://apis.justwatch.com/graphql\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc86a0-6247-4e3a-b29f-53e605197af2",
   "metadata": {},
   "source": [
    "The website **prevents** a robot to get their data **without** specifying a **User-Agent**. Let's create our request headers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43fab464-0202-4ba4-ad53-5b59254eb800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.41 Safari/537.36 Edg/101.0.1210.32\",\n",
    "    \"accept-encoding\": \"gzip, deflate, br\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cd3ec-391c-4ee8-bda1-071d58aeb10b",
   "metadata": {},
   "source": [
    "This project **doesn't aims to explain how the query works, or how it was modified**, but the post data and the query was stored on a file to save us time. \n",
    "\n",
    "Check the following files:\n",
    "\n",
    "- **postData.json**\n",
    "- **query.graphql**\n",
    "\n",
    "Let's **open** those files and **saves to a variable** to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0143e6c-e6a2-4e6c-8c00-387fccf2bfd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/postData.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     post_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open('src/postData.json', 'r', encoding='utf-8') as file:\n",
    "    post_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344b01b-3a86-4fa0-bf86-dba3d0c04f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('src/query.graphql', 'r', encoding='utf-8') as file:\n",
    "    query = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4ad66-6fb4-4ecb-be91-9cab5fc45f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_data['query'] = query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0e5d3-0d69-4bf0-ad63-1d77444986a1",
   "metadata": {},
   "source": [
    "The post data **not specify** which **stream** we will get the data. Let's encapsulate in a function this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f298f1-4ad6-4948-b616-dd671e617856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_streaming(key: str):\n",
    "    \"\"\" Set the streaming on query variables. \"\"\"\n",
    "    \n",
    "    post_data['variables']['popularTitlesFilter']['packages'] = [streamings[key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf7e8d-0e0e-4648-857a-6abac1676844",
   "metadata": {},
   "source": [
    "Some streamings has **over 3k movies and shows**. The query **only returns** a total of **1960 results**, which is not enough to collect all data. \n",
    "\n",
    "To get through this, we will use the **released year filter** to create a **cluster** of items with **below 1960 items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9a6a29-8224-451a-b8b0-dcb8502df737",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [1899, 1950, 1980, 1990, 2000, 2010, 2012, 2014, 2016, 2018, 2020, 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baeb21a-9438-454a-aeb1-91b54be0959e",
   "metadata": {},
   "source": [
    "Let's create a **loop function** to get **all titles available** on a given **streaming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05737a87-6bca-420f-b655-3e1ea034d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(streaming: str, cursor: str = None, titles: list = None, start: bool = True):\n",
    "    \"\"\" Get all titles available of a streaming. \"\"\"\n",
    "    \n",
    "    if not titles:\n",
    "        titles = []\n",
    "    \n",
    "    if cursor and not start:\n",
    "        post_data['variables']['popularAfterCursor'] = cursor\n",
    "    else:\n",
    "        post_data['variables']['popularAfterCursor'] = \"\"\n",
    "    \n",
    "    set_streaming(streaming)\n",
    "    req = requests.post(url, data=json.dumps(post_data), headers=headers)\n",
    "    if req.status_code != 200:\n",
    "        raise requests.ConnectionError('connection failed')\n",
    "    \n",
    "    results = req.json()['data']['popularTitles']\n",
    "    titles.extend(results['edges'])   \n",
    "       \n",
    "    if results['pageInfo']['hasNextPage']:\n",
    "        cursor = results['pageInfo']['endCursor']\n",
    "        get_titles(streaming=streaming, cursor=cursor, titles=titles, start=False)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e0dde-4dcd-4fec-9f1e-87e3de4d7b20",
   "metadata": {},
   "source": [
    "The returned data is well formatted, but it's nested. Let's **parse** the data to a **unique dictionary** containing the correctly fields names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2994c41d-768d-4f92-b0fd-f3e530ce9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_title_content(title: dict):\n",
    "    \"\"\" Parse the title content to a dictionary. \"\"\"\n",
    "    \n",
    "    content = {}\n",
    "    \n",
    "    title = title['node']\n",
    "    content['id'] = title['id']\n",
    "    content['title'] = title['content']['title']\n",
    "    content['type'] = title['objectType']\n",
    "    content['description'] = title['content']['shortDescription']\n",
    "    content['release_year'] = title['content']['originalReleaseYear']\n",
    "    content['age_certification'] = title['content']['ageCertification']\n",
    "    content['runtime'] = title['content']['runtime']\n",
    "    content['genres'] = [i['technicalName'] for i in title['content']['genres']]\n",
    "    content['production_countries'] = title['content']['productionCountries']\n",
    "    content['seasons'] = title.get('totalSeasonCount', None)\n",
    "    content['imdb_id'] = title['content']['externalIds']['imdbId']\n",
    "    content['imdb_score'] = title['content']['scoring']['imdbScore']\n",
    "    content['imdb_votes'] = title['content']['scoring']['imdbVotes']\n",
    "    content['tmdb_popularity'] = title['content']['scoring']['tmdbPopularity']\n",
    "    content['tmdb_score'] = title['content']['scoring']['tmdbScore']\n",
    "    \n",
    "    credits = [\n",
    "        {\n",
    "            'person_id': i['personId'],\n",
    "            'id': content['id'],\n",
    "            'name': i['name'],\n",
    "            'character': i['characterName'],\n",
    "            'role': i['role']\n",
    "        } for i in title['content']['credits']\n",
    "    ]\n",
    "    \n",
    "    return content, credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5113cfcc-f1e8-4642-8080-82efde1a0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_save_data(data: list, save: bool = True, path: str = ''):\n",
    "    \"\"\" Parse a list of titles and save it to a file. \"\"\"\n",
    "    \n",
    "    titles, credits = [], []\n",
    "    for d in data:\n",
    "        t, c = parse_title_content(d)\n",
    "        titles.append(t)\n",
    "        credits.extend(c)\n",
    "    \n",
    "    if save:\n",
    "        titles_df = pd.DataFrame(titles)\n",
    "        titles_df.to_csv(path+'titles.csv', index=False)\n",
    "\n",
    "        credits_df = pd.DataFrame(credits)\n",
    "        credits_df.to_csv(path+'credits.csv', index=False)\n",
    "\n",
    "    return titles, credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6102b-b1d3-40de-beea-a938dafcd03b",
   "metadata": {},
   "source": [
    "All the functions are defined, let's group together to get **all titles available on a streaming**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61294572-0877-4e69-b95e-8d6b1c33ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_titles_by_streaming(streaming: str, save: bool = True, path: str = ''):\n",
    "    \"\"\" Get all titles available on a given streaming. \"\"\"\n",
    "    raw = []\n",
    "    for i in range(len(clusters) - 1):\n",
    "        filter_range = {'min': clusters[i]+1, 'max': clusters[i+1]}\n",
    "        \n",
    "        post_data['variables']['popularTitlesFilter']['releaseYear'] = filter_range  # Set the filter\n",
    "        \n",
    "        cluster_titles = get_titles(streaming=streaming)\n",
    "        raw.extend(cluster_titles)\n",
    "    \n",
    "    if save:\n",
    "        file_path = f'{path}/{streaming}/'\n",
    "        if not os.path.exists(file_path):\n",
    "            os.mkdir(file_path)\n",
    "            \n",
    "    titles, credits = parse_and_save_data(data=raw, save=save, path=file_path)\n",
    "    \n",
    "    return titles, credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3eb23-5ba5-45fb-808d-0c95d3e7e6e9",
   "metadata": {},
   "source": [
    "And now, a function to get **all titles** from **all the streamings**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b72c0f-c64b-48ef-95a5-e097da9c37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_titles(save: bool = True, path:str = ''):\n",
    "    \"\"\" Get all titles available on the available streamings. \"\"\"\n",
    "    \n",
    "    all_titles = {}\n",
    "    for key in tqdm(streamings.keys()):\n",
    "        titles, credits = get_all_titles_by_streaming(streaming=key, save=save, path=path)\n",
    "        all_titles[key] = {'titles': titles, 'credits': credits}\n",
    "    \n",
    "    return all_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca4a38-0dab-4801-8c8a-d2eb751c986c",
   "metadata": {},
   "source": [
    "**Let's save it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6b7a99-959d-4f68-8616-6a3dbf49e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5083b3796e43d0898331badf1d3639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5806"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_all_titles(save=True, path='data')\n",
    "len(data['netflix']['titles'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
